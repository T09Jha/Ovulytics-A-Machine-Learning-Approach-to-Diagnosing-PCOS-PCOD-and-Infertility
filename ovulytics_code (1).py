# -*- coding: utf-8 -*-
"""Ovulytics-code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GVEpZVthX6zpPOCNNVe68JMkr6eU6Id7
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import sklearn as sk
import seaborn as sns
from scipy import stats
#pip install imbalanced-learn
import imblearn
from imblearn.over_sampling import SMOTE

import warnings

warnings.filterwarnings('ignore')

df=pd.read_csv('final_dataset_pcos_f.csv')
df_pd=pd.read_csv('period - Copy (1).csv')
df_in=pd.read_csv('PCOS_infertility.csv')

#Analysis for PCOS
df.head()
df.duplicated().sum()
df.isnull().sum()
df.describe()

#Analysis for PCOD
df_pd.duplicated().sum()
df_pd.isnull().sum()

#Analysis for PCOS with infertility
print(df_in.columns)
df_in.describe()

print("Number of Rows",df.shape[0])
print("Number of Columns",df.shape[1])
print(df.columns)

print("Number of Rows",df_pd.shape[0])
print("Number of Columns",df_pd.shape[1])
print(df_pd.columns)

print("Number of Rows",df_in.shape[0])
print("Number of Columns",df_in.shape[1])
print(df_in.columns)

# Updated conversion function
def convert_height_to_inches(height_str):
    try:
        # Handle heights formatted as "X feet Y inches"
        if " " in height_str:
            parts = height_str.split()
            if len(parts) == 2:  # Ensure it's two parts
                feet, inches = float(parts[0]), float(parts[1])
                return feet * 12 + inches

        # Handle heights given as decimal feet (e.g., "2.5")
        elif "." in height_str:
            feet = float(height_str)
            return feet * 12

        # Handle heights given as whole feet (e.g., "2")
        else:
            feet = int(height_str)
            return feet * 12

    except ValueError:
        # Return None if the height format is invalid
        return None

# Apply the function to the DataFrame
df_pd['Height_inches'] = df_pd['Height'].apply(convert_height_to_inches)

# Calculate the mean height
height_mean = df_pd['Height_inches'].mean()
print("Mean Height (inches):", height_mean)

#Box plot for PCOS
cols_pcos = ['Age', 'TSH', 'Follicle No.', 'BMI','AMH','I beta-HCG']

for col in cols_pcos:

    plt.figure(figsize=(13, 2))
    sns.boxplot(x=df[col],palette='Blues')
    plt.title(f'Box plot of {col} Column', fontsize=15 )

#Box plot for PCOD
cols_pcod =['Age', 'Weight','Length_of_cycle','Estimated_day_of_ovulution','Menses_score']
for col in cols_pcod:
  plt.figure(figsize=(13, 2))
  sns.boxplot(x=df_pd[col],palette='Blues')
  plt.title(f'Box plot of {col} Column', fontsize=15 )

#Box plot for PCOS with infertility
cols_in=['I beta-HCG(mIU/mL)', 'II beta-HCG(mIU/mL)','AMH(ng/mL)']
for col in cols_in:
  plt.figure(figsize=(13, 2))
  sns.boxplot(x=df_in[col],palette='Blues')
  plt.title(f'Box plot of {col} Column', fontsize=15 )

#Outlier count for PCOS
for col in cols_pcos:

    column = df[col]
    Q1 = column.quantile(0.25)
    Q3 = column.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = column[(column < lower_bound) | (column > upper_bound)]
    num_outliers = len(outliers)
    print(f"Column '{col}' has {num_outliers} outliers.")

#Outlier Removal
z_scores = stats.zscore(df.select_dtypes(include=['number']))
threshold = 3
outlier_indices = (abs(z_scores) > threshold).any(axis=1)
clean_df = df[~outlier_indices]
clean_df.reset_index(drop=True, inplace=True)

#Outlier Count for PCOD
for col in cols_pcod:

    column = df_pd[col]
    Q1 = column.quantile(0.25)
    Q3 = column.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = column[(column < lower_bound) | (column > upper_bound)]
    num_outliers = len(outliers)
    print(f"Column '{col}' has {num_outliers} outliers.")

#Outlier removal
z_scores = stats.zscore(df.select_dtypes(include=['number']))
threshold = 3
outlier_indices = (abs(z_scores) > threshold).any(axis=1)
clean_df = df[~outlier_indices]
clean_df.reset_index(drop=True, inplace=True)
num_outliers_removed = len(df) - len(clean_df)

print("Number of outliers removed:", num_outliers_removed)

print("Number of Rows",df.shape[0])
print("Number of Columns",df.shape[1])

for col in cols_pcod:
    column = df_pd[col]
    Q1 = column.quantile(0.25)
    Q3 = column.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = column[(column < lower_bound) | (column > upper_bound)]
    num_outliers = len(outliers)
    print(f"Column '{col}' has {num_outliers} outliers.")

#Outlier handling for PCOS with infertility
import numpy as np
X = df_in.drop(columns=['Sl. No', 'Patient File No.', 'PCOS (Y/N)'])

non_repeated_values = X['II beta-HCG(mIU/mL)'][X['II beta-HCG(mIU/mL)'] != 1.99]
df_in['II beta-HCG(mIU/mL)'] = df_in['II beta-HCG(mIU/mL)'].apply(lambda x: np.random.choice(non_repeated_values) if x == 1.99 else x)

non_repeated_values = X['I beta-HCG(mIU/mL)'][X['I beta-HCG(mIU/mL)'] != 1.99]
df_in['I beta-HCG(mIU/mL)'] = df_in['I beta-HCG(mIU/mL)'].apply(lambda x: np.random.choice(non_repeated_values) if x == 1.99 else x)

#Mean Count for PCOS
df['mean_column'] = df['I beta-HCG'].copy()
mean_value = df['I beta-HCG'].mean()
df.loc[df['I beta-HCG'].duplicated(), 'mean_column'] = mean_value
df.drop(columns=['I beta-HCG'], inplace=True)
df.rename(columns={'mean_column': 'I beta-HCG'}, inplace=True)

df['II beta-HCG'] = df['II beta-HCG'].astype(str)
split_values = df['II beta-HCG'].str.split('.', expand=True)
numeric_values = split_values.apply(pd.to_numeric, errors='coerce')
df[['II beta-HCG_part1', 'II beta-HCG_part2']] = numeric_values
print(df.head())

#Application of smote technique for balancing for PCOS
import imblearn
from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
x = df.drop(columns=['PCOS'])
y = df['PCOS']

xts, yts = smote.fit_resample(x, y)

df_resampled = xts.copy()
df_resampled['PCOS'] = yts

print("Values after balancing :",len(yts))
print("Values before balancing :",len(y))

#identification of outliers after applying smote

for col in cols_pcos:

    column = df[col]
    Q1 = column.quantile(0.25)
    Q3 = column.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = column[(column < lower_bound) | (column > upper_bound)]
    num_outliers = len(outliers)
    print(f"Column '{col}' has {num_outliers} outliers.")

columns_to_handle = ['Age', 'Weight', 'Height', 'BMI', 'Pulse rate', 'BP _Systolic', 'BP _Diastolic ']

def replace_outliers_with_nan(df, col):
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df.loc[(df[col] < lower_bound) | (df[col] > upper_bound), col] = float('NaN')
    return df

for col in columns_to_handle:
    df = replace_outliers_with_nan(df, col)

for col in columns_to_handle:
    df = replace_outliers_with_nan(df, col)
for col in cols_pcos:

    column = df[col]
    Q1 = column.quantile(0.25)
    Q3 = column.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = column[(column < lower_bound) | (column > upper_bound)]
    num_outliers = len(outliers)
    print(f"Column '{col}' has {num_outliers} outliers.")

from sklearn.impute import SimpleImputer

columns_to_handle = ['Age', 'Weight', 'Height', 'BMI', 'Pulse rate', 'BP _Systolic', 'BP _Diastolic ']

def replace_outliers_with_nan(df, col):
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df.loc[(df[col] < lower_bound) | (df[col] > upper_bound), col] = float('NaN')
    return df

for col in columns_to_handle:
    df = replace_outliers_with_nan(df, col)

imputer = SimpleImputer(strategy='mean')
df[columns_to_handle] = imputer.fit_transform(df[columns_to_handle])

smote = SMOTE(random_state=42)
x = df.drop(columns=['PCOS'])
y = df['PCOS']

xts, yts = smote.fit_resample(x, y)

df1_resampled = xts.copy()
df1_resampled['PCOS'] = yts

print("Values after balancing :",len(yts))
print("Values before balancing :",len(y))

#PCOS Prediction
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.feature_selection import RFECV
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

X = df.drop('PCOS', axis=1)
y = df['PCOS']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

logistic_model = LogisticRegression(max_iter=1000)
random_forest_model = RandomForestClassifier(random_state=42)
xgb_model = XGBClassifier(random_state=42)

# Perform RFECV for Logistic Regression, Random Forest, XGBoost
rfecv_logistic = RFECV(estimator=logistic_model, step=1, cv=StratifiedKFold(5), scoring='accuracy')
rfecv_logistic.fit(X_train, y_train)

rfecv_rf = RFECV(estimator=random_forest_model, step=1, cv=StratifiedKFold(5), scoring='accuracy')
rfecv_rf.fit(X_train, y_train)

rfecv_xgb = RFECV(estimator=xgb_model, step=1, cv=StratifiedKFold(5), scoring='accuracy')
rfecv_xgb.fit(X_train, y_train)

X_train_selected_logistic = rfecv_logistic.transform(X_train)
X_test_selected_logistic = rfecv_logistic.transform(X_test)
print(f"Logistic Regression optimal number of features: {rfecv_logistic.n_features_}")

X_train_selected_rf = rfecv_rf.transform(X_train)
X_test_selected_rf = rfecv_rf.transform(X_test)
print(f"Random Forest optimal number of features: {rfecv_rf.n_features_}")

X_train_selected_xgb = rfecv_xgb.transform(X_train)
X_test_selected_xgb = rfecv_xgb.transform(X_test)
print(f"XGBoost optimal number of features: {rfecv_xgb.n_features_}")

models = {
    "Logistic Regression": (logistic_model, X_train_selected_logistic, X_test_selected_logistic),
    "Random Forest": (random_forest_model, X_train_selected_rf, X_test_selected_rf),
    "XGBoost": (xgb_model, X_train_selected_xgb, X_test_selected_xgb),
}

for model_name, (model, X_train_selected, X_test_selected) in models.items():
    model.fit(X_train_selected, y_train)

    y_pred = model.predict(X_test_selected)

    accuracy = accuracy_score(y_test, y_pred)
    conf_matrix = confusion_matrix(y_test, y_pred)
    class_report = classification_report(y_test, y_pred)

    print(f"\n{model_name} Results:")
    print(f"Accuracy: {accuracy:.4f}")
    print("Confusion Matrix:")
    print(conf_matrix)
    print("Classification Report:")
    print(class_report)

def predict_pcos_likelihood():
    print("\n--- PCOS Likelihood Prediction ---")
    user_input = {}

    for feature in selected_features:
        while True:
            try:
                user_value = input(
                    f"Enter your {feature} (leave blank for default mean; if Y enter 1, if N enter 0): "
                )
                if user_value.strip() == "":
                    user_value = df[feature].mean()
                else:
                    user_value = float(user_value)
                user_input[feature] = user_value
                break
            except ValueError:
                print("Invalid input. Please enter a numeric value.")

    input_df = pd.DataFrame([user_input], columns=selected_features)
    input_scaled = scaler.transform(input_df)

    pcos_prob = rf_classifier.predict_proba(input_scaled)[:, 1]
    likelihood_percentage = np.round(pcos_prob * 100, 2)

    print(f"\nThe likelihood of PCOS is: {likelihood_percentage[0]}%")

predict_pcos_likelihood()

#Predict PCOD
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.feature_selection import RFECV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

df_pd['Unusual_Bleeding'] = df_pd['Unusual_Bleeding'].apply(lambda x: 1 if x == 'yes' else 0)

default_cycle_range = [21, 35]
default_ovulation_range = [12, 16]
default_bmi_threshold = 25
default_menses_threshold = 3

def heuristic_pcod_label(row):
    probability = 0

    if row['Length_of_cycle'] < default_cycle_range[0] or row['Length_of_cycle'] > default_cycle_range[1]:
        probability += 1
    if row['Estimated_day_of_ovulution'] < default_ovulation_range[0] or row['Estimated_day_of_ovulution'] > default_ovulation_range[1]:
        probability += 1
    if row['BMI'] > default_bmi_threshold:
        probability += 1
    if row['Unusual_Bleeding'] == 1:
        probability += 1
    if row['Menses_score'] > default_menses_threshold:
        probability += 1

    return 1 if probability >= 3 else 0

df_pd['PCOD'] = df_pd.apply(heuristic_pcod_label, axis=1)

X = df_pd[['Length_of_cycle', 'Estimated_day_of_ovulution', 'BMI', 'Unusual_Bleeding', 'Menses_score']]
y = df_pd['PCOD']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rfecv = RFECV(estimator=rf_classifier, step=1, cv=StratifiedKFold(5), scoring='accuracy')
rfecv.fit(X_train, y_train)

selected_features = X.columns[rfecv.support_].tolist()
print("Selected Features:", selected_features)

X_train_selected = rfecv.transform(X_train)
X_test_selected = rfecv.transform(X_test)

rf_classifier.fit(X_train_selected, y_train)

y_test_pred = rf_classifier.predict(X_test_selected)
print("\nClassification Report:")
print(classification_report(y_test, y_test_pred))
train_accuracy = accuracy_score(y_train, rf_classifier.predict(rfecv.transform(X_train)))
test_accuracy = accuracy_score(y_test, y_test_pred)
print(f"Training Accuracy: {train_accuracy:.2f}")
print(f"Testing Accuracy: {test_accuracy:.2f}")

print("\n--- PCOD Prediction ---")

user_cycle_length = int(input("Enter Cycle length (e.g., 40): "))
user_ovulation_day = int(input("Enter Ovulation day (e.g., 12): "))
user_bmi = float(input("Enter BMI (e.g., 29): "))
user_unusual_bleeding = int(input("Enter Unusual Bleeding (1 for yes, 0 for no): "))
user_menses_score = int(input("Enter Menses score (e.g., 5): "))

# Create a dataframe for user input
user_input = pd.DataFrame({
    'Length_of_cycle': [user_cycle_length],
    'Estimated_day_of_ovulution': [user_ovulation_day],
    'BMI': [user_bmi],
    'Unusual_Bleeding': [user_unusual_bleeding],
    'Menses_score': [user_menses_score]
})
user_input_transformed = rfecv.transform(user_input)

user_prediction_proba = rf_classifier.predict_proba(user_input_transformed)[:, 1]
print(f"Predicted PCOD Probability for User Input: {user_prediction_proba[0] * 100:.2f}%")

#PCOS with infertility prediction
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.feature_selection import RFECV
from sklearn.ensemble import RandomForestRegressor
import numpy as np

df_in.columns = df_in.columns.str.strip()

cleaned_data = df_in.drop(columns=['Sl. No', 'Patient File No.'])

X = cleaned_data.drop(columns=['PCOS (Y/N)'])
y = cleaned_data['PCOS (Y/N)']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rfecv = RFECV(estimator=rf_model, step=1, cv=StratifiedKFold(5), scoring='r2')
rfecv.fit(X_train, y_train)

selected_features = X.columns[rfecv.support_].tolist()
print(f"Selected Features: {selected_features}")

X_train_selected = rfecv.transform(X_train)
X_test_selected = rfecv.transform(X_test)
rf_model.fit(X_train_selected, y_train)
def predict_infertility():
    user_input_data = {}
    for feature in selected_features:
        user_input_data[feature] = [float(input(f"Enter {feature}: "))]

    user_input = pd.DataFrame(user_input_data)

    user_input_transformed = rfecv.transform(user_input)

    prediction = rf_model.predict(user_input_transformed)

    infertility_chances_percentage = prediction[0] * 100
    print(f'Predicted Infertility Chances: {infertility_chances_percentage:.2f}%')

predict_infertility()